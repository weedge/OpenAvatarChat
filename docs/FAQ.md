# ğŸš¨FAQs | å¸¸è§é—®é¢˜ğŸš¨

> [!NOTE]
> Please avoid creating issues regarding the following questions, as they might be closed without a response.
> 
> è¯·é¿å…åˆ›å»ºä¸ä¸‹è¿°é—®é¢˜æœ‰å…³çš„ issuesï¼Œè¿™äº› issues å¯èƒ½ä¸ä¼šè¢«å›å¤ã€‚


## Deployment Related Issues / éƒ¨ç½²ç›¸å…³é—®é¢˜

### Environment Configuration / ç¯å¢ƒé…ç½®

**Q: What operating systems are supported by the project? / é¡¹ç›®æ”¯æŒå“ªäº›æ“ä½œç³»ç»Ÿ**  

Currently supports Linux and Windows.  
ç›®å‰æ”¯æŒLinuxå’ŒWindowsã€‚

```
The LAM can be run on a mac, just remove cuda related dependencies like onnxruntime-gpu to run on a cpu!
LAM éƒ¨åˆ†å¯ä»¥ä½¿ç”¨macè¿è¡Œï¼Œåªéœ€ç§»é™¤cuda ç›¸å…³çš„ä¾èµ–ï¼Œæ¯”å¦‚onnxruntime-gpuï¼Œå°±å¯ä»¥åœ¨cpu ä¸Šè¿è¡Œ
```

### Dependency Installation / ä¾èµ–å®‰è£…

**Q: How to resolve onnxruntime-gpu installation failure? / å®‰è£… onnxruntime-gpu å¤±è´¥æ€ä¹ˆåŠï¼Ÿ**  

1. Verify CUDA version compatibility  
2. Check Python version compatibility  
3. Try installing via conda environment  
4. Pay attention to platform compatibility (manylinux_2_27_x86_64, manylinux_2_28_x86_64, win_amd64)  
<!-- new list start -->

1. ç¡®è®¤ CUDA ç‰ˆæœ¬å…¼å®¹æ€§  
2. æ£€æŸ¥ Python ç‰ˆæœ¬æ˜¯å¦åŒ¹é…  
3. å°è¯•ä½¿ç”¨ conda ç¯å¢ƒå®‰è£…  
4. æ³¨æ„å¹³å°å…¼å®¹æ€§ï¼ˆmanylinux_2_27_x86_64, manylinux_2_28_x86_64, win_amd64ï¼‰

---

**Q: Is RTX 50 supported / 50ç³»æ˜¾å¡æ˜¯å¦æ”¯æŒ**
Currently, 50 series need to use cuda12.8 or above, the corresponding pytorch-related packages need to be installed as version 12.8.
ç›®å‰50ç³»æ˜¾å¡éœ€è¦ä½¿ç”¨cuda12.8ä»¥ä¸Šï¼Œå¯¹åº”pytorchç›¸å…³çš„åŒ…éœ€è¦å®‰è£…æˆ12.8çš„ç‰ˆæœ¬
```
#https://pytorch.org/get-started/locally/
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
```
---

**Q: Is CPU(or mac) supported / çº¯CPUæˆ–è€…macæœºå™¨æ˜¯å¦èƒ½éƒ¨ç½²**
It can only run smoothly with config/chat_with_gs.yaml, but the lite-avatar self-test won't run. It seems like have to manually change all device to mps to make it work.
åªèƒ½é¡ºç•…çš„è¿è¡Œ config/chat_with_gs.yaml, lite-avatar è‡ªæµ‹è·‘ä¸åŠ¨ï¼Œä¼°è®¡è¦å…¨éƒ¨æ‰‹åŠ¨æ”¹æˆ mps æ‰å¯èƒ½ã€‚
```
#è¿è¡Œchat_with_gs.yaml æ‰€éœ€é¢å¤–æ­¥éª¤
#ç¬¬ä¸€æ­¥ï¼šç§»é™¤torchvision ä¾èµ–
#ç¬¬äºŒæ­¥ï¼šæ›¿æ¢onnxruntime-gpu ä¸º onnxruntime ä¾èµ–
#ä¿®æ”¹ src/handlers/avatar/lam/LAM_Audio2Expression/engines/infer.py ,åˆ é™¤æ‰€æœ‰.cuda()æ–¹æ³•çš„è°ƒç”¨
#æŒ‰ç…§readme æŒ‰ç…§ä¾èµ–ï¼Œå¹¶è¿è¡Œå³å¯

```


```
#https://pytorch.org/get-started/locally/
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
```
---

**Q: How to resolve pynini installation issues? / pynini å®‰è£…å‡ºç°é—®é¢˜æ€ä¹ˆåŠï¼Ÿ**  

Refer to the cosyvoice module installation section in README.  
æŸ¥çœ‹readmeä¸­å…³äºcosyvoiceæ¨¡å—å®‰è£…çš„éƒ¨åˆ†ã€‚

---

**Q: Error: fastrtc-0.0.19.dev0-py3-none-any.whl not found during installation / å®‰è£…æŠ¥é”™æ–‡ä»¶fastrtc-0.0.19.dev0-py3-none-any.whlä¸å­˜åœ¨**  

This error indicates incomplete submodule retrieval. Re-pull submodules from the project root directory.  
è¿™ä¸ªæŠ¥é”™è¯´æ˜å­æ¨¡å—æ²¡æœ‰å…¨éƒ¨æ‹‰ä¸‹æ¥ã€‚åœ¨é¡¹ç›®æ ¹ç›®å½•é‡æ–°æ‹‰å–å­æ¨¡å—ã€‚

---

**Q: Error related to 'gbk' encoding on Windows / windowsä¸‹å‡ºç°'gbk'ç¼–ç ç›¸å…³çš„é”™è¯¯**

Manually set environment variable PYTHONUTF8=1.  
å¯ä»¥æ‰‹åŠ¨è®¾ç½®ç¯å¢ƒå˜é‡PYTHONUTF8=1ã€‚

---

**Q: Error when running deployment after pip install requirements.txt / ä½¿ç”¨pip installå®‰è£…å¯¹åº”çš„requirements.txtï¼Œéƒ¨ç½²è¿è¡Œæ—¶æŠ¥é”™**  

Project dependencies are modularized. The root requirements.txt contains only public dependencies. Use uv for installation, or manually install required module dependencies based on .toml files.  
é¡¹ç›®ä¾èµ–ä»¥æ¨¡å—åŒ–çš„æ–¹å¼å­˜æ”¾ï¼Œæ ¹ç›®å½•ä¸‹çš„requirements.txtåªåŒ…å«å…¬å…±ä¾èµ–ã€‚è¯·ä½¿ç”¨uvè¿›è¡Œä¾èµ–å®‰è£…ï¼Œæˆ–è€…æ ¹æ®éœ€è¦ç”¨åˆ°çš„æ¨¡å—ä¸‹çš„.tomlæ–‡ä»¶ï¼Œæ‰‹åŠ¨å®‰è£…æ‰€éœ€æ¨¡å—çš„å¯¹åº”ä¾èµ–ã€‚

### Deployment Issues / éƒ¨ç½²é—®é¢˜

**Q: AutoDL deployment of TURN Server fails to enable remote access? / AutoDLéƒ¨ç½²äº†TURN Serverä¹‹åè¿˜æ˜¯ä¸èƒ½è¿œç¨‹æ‰“å¼€ï¼Ÿ**  

AutoDL does not allow personal users to open custom ports, remote login unavailable.  
AutoDLä¸æ”¯æŒä¸ªäººç”¨æˆ·å¼€å¯è‡ªå®šä¹‰ç«¯å£ï¼Œæ— æ³•è¿œç¨‹ç™»å½•ã€‚

## Runtime Related Issues / è¿è¡Œç›¸å…³é—®é¢˜

### Performance Issues / æ€§èƒ½é—®é¢˜

**Q: Intermittent lag when using minicpm as LLM on 4090 / 4090ä¸‹ä½¿ç”¨minicpmä½œä¸ºllmï¼Œå¯¹è¯è¿‡ç¨‹ä¸­æ—¶ä¸æ—¶å­˜åœ¨å¡é¡¿**

Non-quantized minicpm shows lag on 4090. Recommend switching LLM to API call or using non-multimodal local models.  
minicpméé‡åŒ–ç‰ˆæœ¬åœ¨4090ä¸Šæµ‹è¯•ä¸‹æ¥æ˜¯ä¼šå­˜åœ¨å¡é¡¿ï¼Œå»ºè®®llmæ”¹ç”¨apiè°ƒç”¨ï¼Œæˆ–è€…æœ¬åœ°çš„éå¤šæ¨¡æ€æ¨¡å‹ã€‚

## Audio Related Issues / è¯­éŸ³ç›¸å…³é—®é¢˜

### TTS Model / TTS æ¨¡å‹

**Q: How to resolve audio model lag? / è¯­éŸ³æ¨¡å‹å¡é¡¿æ€ä¹ˆè§£å†³ï¼Ÿ** 

For local cosyvoice, check GPU memory usage and adjust batch size in config. Switch to API call if needed. For API lag, check network issues and API response latency.  
å¦‚æœè°ƒç”¨çš„æ˜¯æœ¬åœ°çš„cosyvoiceï¼Œè¯·æ£€æŸ¥GPUæ˜¾å­˜ä½¿ç”¨æƒ…å†µï¼Œå¯ä»¥åœ¨é…ç½®æ–‡ä»¶ä¸­è°ƒæ•´æ‰¹å¤„ç†å¤§å°ã€‚æˆ–è€…æ”¹ä¸ºAPIè°ƒç”¨ã€‚å¦‚æœæ˜¯APIè°ƒç”¨å¡é¡¿ï¼Œè¯·æ’æŸ¥ç½‘ç»œé—®é¢˜å’ŒAPIæœ¬èº«çš„è°ƒç”¨è¿”å›å»¶è¿Ÿã€‚

### Audio Interaction / è¯­éŸ³äº¤äº’

**Q: How to improve speech recognition accuracy? / è¯­éŸ³è¯†åˆ«ä¸å‡†ç¡®æ€ä¹ˆåŠï¼Ÿ**  

1. Check microphone settings  
2. Ensure low ambient noise  
3. Adjust speech recognition parameters  
<!-- new list start -->

1. æ£€æŸ¥éº¦å…‹é£è®¾ç½®  
2. ç¡®ä¿ç¯å¢ƒå™ªéŸ³è¾ƒå°  
3. è°ƒæ•´è¯­éŸ³è¯†åˆ«å‚æ•°

## Feature Usage / åŠŸèƒ½ä½¿ç”¨

### Digital Human / æ•°å­—äºº

**Q: How to customize digital human appearance? / å¦‚ä½•è‡ªå®šä¹‰æ•°å­—äººå¤–è§‚ï¼Ÿ**

LiteAvatar does not support customization but provides [official character library](https://modelscope.cn/models/HumanAIGC-Engineering/LiteAvatarGallery). LAM supports customization via [Git project](https://github.com/aigc3d/LAM).  
LiteAvataræš‚ä¸æ”¯æŒè‡ªå®šä¹‰ï¼Œä½†å¯ä»¥ä½¿ç”¨[å®˜æ–¹å½¢è±¡åº“](https://modelscope.cn/models/HumanAIGC-Engineering/LiteAvatarGallery)ã€‚LAM æ•°å­—äººæ”¯æŒè‡ªå®šä¹‰ï¼Œå‚è€ƒå¯¹åº”çš„[gité¡¹ç›®åœ°å€](https://github.com/aigc3d/LAM)ã€‚

---

**Q: How to change digital human models? / å¦‚ä½•æ›´æ¢æ•°å­—äººæ¨¡å‹ï¼Ÿ**  

Locate the target character and modify the appearance parameters in config file.  
æ‰¾åˆ°å¯¹åº”æƒ³ä¿®æ”¹çš„è§’è‰²ï¼Œç„¶åæ›´æ¢configæ–‡ä»¶ä¸­å¯¹åº”çš„å½¢è±¡å‚æ•°ã€‚

---

**Q: How to enable model vision capabilities and how are they implemented? / æ€ä¹ˆå¼€å¯æ¨¡å‹çš„è§†è§‰åŠŸèƒ½ã€‚æ¨¡å‹çš„è§†è§‰å…·ä½“æ˜¯å¦‚ä½•å®ç°çš„** 

Select model IDs with vision capabilities like qwen_vl via API, or use local multimodal models. Implementation combines LLM with the last captured video frame during user interaction.  
åœ¨apiè°ƒç”¨æ—¶é€‰æ‹©å…·æœ‰è§†è§‰åŠŸèƒ½çš„model idå¦‚qwen_vlï¼Œæˆ–ä½¿ç”¨æœ¬åœ°çš„å¤šæ¨¡æ€æ¨¡å‹ã€‚å…·ä½“å®ç°æ˜¯å°†ç”¨æˆ·å¯¹è¯æ—¶æ‘„åƒå¤´æ•è·åˆ°çš„æœ€åä¸€å¸§ç”»é¢ä¸€èµ·æäº¤ç»™llmã€‚

---

**Q: Does the project support multi-channel concurrency? / é¡¹ç›®ç›®å‰æ”¯æŒå¤šè·¯å¹¶å‘å—ï¼Ÿ**

LiteAvatar does not support concurrency while LAM supports it via configuration file changes.  
ç›®å‰LiteAvataræ•°å­—äººä¸æ”¯æŒå¤šè·¯å¹¶å‘ï¼ŒLAMæ•°å­—äººæ”¯æŒå¤šè·¯å¹¶å‘ï¼Œå¯ä»¥åœ¨å¯¹åº”é…ç½®æ–‡ä»¶ä¸­ä¿®æ”¹ã€‚

---
**Q: Where is the front-end code? / å‰ç«¯ä»£ç åœ¨å“ªé‡Œï¼Ÿ**
gradio_webrtc in the git submodule, which contains wrappers for webrtc functionality and UI-related code
git submodule ä¸­çš„ gradio_webrtcï¼Œè¿™ä¸ªç»„ä»¶åŒ…å«äº†webrtc åŠŸèƒ½çš„å°è£…å’Œ UI ç›¸å…³çš„ä»£ç 

Pathï¼šOpenAvatarChat\src\third_party\gradio_webrtc_videochat
Linkï¼š https://github.com/HumanAIGC-Engineering/gradio-webrtc.git

### Integrated Features / é›†æˆåŠŸèƒ½

**Q: How to configure Turn Server? / å¦‚ä½•é…ç½® Turn Serverï¼Ÿ**  

Refer to Turn Server configuration README.  
å‚è€ƒTurn Serveré…ç½®çš„readmeã€‚


## Best Practices / æœ€ä½³å®è·µ

1. Use officially recommended configuration environment  
2. Pull latest code  
3. Maintain environment isolation using uv for dependency management  
<!-- new list start -->

1. ä½¿ç”¨å®˜æ–¹æ¨èçš„é…ç½®ç¯å¢ƒ  
2. æ‹‰å–æœ€æ–°ä»£ç   
3. åšå¥½ç¯å¢ƒéš”ç¦»ï¼Œä½¿ç”¨uvè¿›è¡Œä¾èµ–ç®¡ç†å’Œé…ç½®

> [!Tip]
> If the problems still exist with the latest code, please create an issue.
> è‹¥ä½¿ç”¨æœ€æ–°çš„ä»£ç ä»ç„¶æ— æ³•è§£å†³é—®é¢˜ï¼Œè¯·åˆ›å»ºä¸€ä¸ª issueã€‚
